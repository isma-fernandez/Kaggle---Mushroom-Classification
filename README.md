# Projecte de Machine Learning: Kaggle Playground Series S4E8 - Mushroom Classification

Aquest projecte utilitza el dataset del concurs [Playground Series S4E8](https://www.kaggle.com/competitions/playground-series-s4e8/submissions) organitzat per Kaggle. La competici√≥ implica desenvolupar models de Machine Learning per a la classificaci√≥ bin√†ria utilitzant un dataset proporcionat per Kaggle.

## ‚ú® Descripci√≥ del projecte

El projecte explora i optimitza tres dels models m√©s potents en Machine Learning: **CatBoost**, **XGBoost** i **LightGBM**. Tamb√© es desenvolupen experiments amb altres algoritmes per contrastar el rendiment i trobar una combinaci√≥ √≤ptima. Es fan servir diferents t√®cniques d'optimitzaci√≥ i ajust de par√†metres per aconseguir el millor rendiment possible en la competici√≥, juntament amb un preprocessament de les dades abastant el tractament de outliers, valors "null", codificaci√≥ tant de caracter√≠stiques categ√≤riques com ordinals i el target, eliminaci√≥ de columnes no rellevant a partir de la correlaci√≥ amb la variable objectiu i la normalitzaci√≥ del dataset.

---

## üìù Contingut del projecte

Cont√© els notebooks amb experiments detallats que implementen:
- Divisi√≥ de dades amb `train_test_split` i estrat√®gies avan√ßades com `StratifiedKFold`.
- Codificaci√≥ utilitzant eines com `LabelEncoder`, `OrdinalEncoder` i `OneHotEncoder`.
- Normalitzaci√≥ i escalat amb `StandardScaler`.
- Selecci√≥ i transformaci√≥ de caracter√≠stiques amb t√®cniques com PCA (An√†lisi de Components Principals).

---

## ‚öôÔ∏è Models utilitzats

1. **XGBoost**:
   - Model basat en gradient boosting.
   - Utilitzat amb ajustos d'hiperpar√†metres com `n_estimators`, `max_depth` i `learning_rate`.

2. **CatBoost**:
   - Model basat en gradient boosting amb suport natiu per a variables categ√≤riques.
   - Implementat amb par√†metres ajustables com `iterations`, `depth`, i `bagging_temperature`.

3. **LightGBM (LGBM)**:
   - Model optimitzat per a grans datasets i alta velocitat d'entrenament.
   - Ajustos d'hiperpar√†metres com `num_leaves`, `max_depth`, i `learning_rate`.
   - Implementaci√≥ nativa de Gradient Boosting Decision Tree (GBDT).

4. **Altres models explorats**:
   - **Logistic Regression**: Base lineal.
   - **Random Forest**: Model d'ensemble basat en arbres de decisi√≥.
   - **Support Vector Machines (SVM)**: Algoritme lineal i no lineal.
   - **Decision Trees**: Model explicatiu per caracter√≠stiques simples.

---

## ‚öôÔ∏è Metodologies d'Avaluaci√≥

- M√®triques:
  - `accuracy_score`, `f1_score`, i `matthews_corrcoef` per analitzar el rendiment.
- Cross-validation:
  - Implementada amb `cross_val_score` i CV espec√≠fic per XGBoost (`xgb_cv`), CatBoost (`catboost_cv`) i LightGBM (`lgb.cv`).

---

## üìÇ Requeriments

Aquest projecte utilitza **Python** i diverses biblioteques. Assegura't de tenir-les instal¬∑lades:

```bash
pip install catboost xgboost lightgbm pandas numpy scikit-learn matplotlib